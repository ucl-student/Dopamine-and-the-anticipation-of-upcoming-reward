{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from random import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(y): #probability of reward\n",
    "    if random() <= y:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trialgenerator(n, y): #generating 1000 trials for the two levers; the levers switch probabilities every 10-32 trials\n",
    "    left_reward = []\n",
    "    right_reward = []\n",
    "    left_correct = []\n",
    "    right_correct = []\n",
    "    for trials in np.arange(50):\n",
    "        for x in np.arange(randint(10,32)):\n",
    "            left_reward.append(prob(n))\n",
    "            right_reward.append(prob(y))\n",
    "            left_correct.append(1)   #correct is 1 when reward probability is higher and 0 when lower\n",
    "            right_correct.append(0)\n",
    "        for x in np.arange(randint(10,32)):\n",
    "            left_reward.append(prob(y))\n",
    "            right_reward.append(prob(n))\n",
    "            left_correct.append(0)\n",
    "            right_correct.append(1)\n",
    "    del left_correct [1000:] #deleting everything after 1000 trials\n",
    "    del right_correct [1000:]\n",
    "    del left_reward[1000:]\n",
    "    del right_reward[1000:]\n",
    "    return left_reward, right_reward, left_correct, right_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lever_update(alpha, value, reward):\n",
    "    value += alpha * (reward - value) \n",
    "    return(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(beta, temp_value1, temp_value2):   #temp_value1 is for left lever and temp_value2 is for right lever\n",
    "    num = np.exp(temp_value1 * beta)\n",
    "    den = np.exp(temp_value1 * beta) + np.exp(temp_value2 * beta)    \n",
    "    return num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(alpha, beta, left_reward, right_reward, left_correct, right_correct):\n",
    "    right_value = [0.5]\n",
    "    left_value = [0.5]\n",
    "    correct = []\n",
    "    for index, lr in enumerate(left_reward):\n",
    "        if random() <= softmax(beta, left_value[-1], right_value[-1]):\n",
    "            left_value.append(lever_update(alpha, left_value[-1], left_reward[index]))\n",
    "            right_value.append(right_value[-1])\n",
    "            correct.append(left_correct[index])\n",
    "        else:\n",
    "            right_value.append(lever_update(alpha, right_value[-1], right_reward[index]))\n",
    "            left_value.append(left_value[-1])\n",
    "            correct.append(right_correct[index])\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_choices = {} \n",
    "for x in np.arange(0,1.05,0.05): #range of alphas 0 to 1\n",
    "    x = round(x, 3)\n",
    "    correct_choices[x] = {}\n",
    "    for y in np.arange(0,5.1,0.1): #range of beta from 0 to 5\n",
    "        y = round(y, 3)\n",
    "        correct_choices[x][y] = {}\n",
    "        correct_list = []\n",
    "        for n in range(10):\n",
    "            left_reward, right_reward, left_correct, right_correct = trialgenerator(0.7, 0.1)  #setting reward for left lever\n",
    "            correct_list.append(sim(x, y, left_reward, right_reward, left_correct, right_correct))\n",
    "        correct_choices[x][y] = correct_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = []\n",
    "for y in np.arange(0,5.1,0.1):\n",
    "    y = round(y, 3)\n",
    "    heatmap.append([np.mean(correct_choices[x][y]) for x in correct_choices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3a = pd.DataFrame(heatmap, index = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2, 2.1, 2.2, 2.3, 2.4, 2.5,2.6, 2.7, 2.8, 2.9, 3, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5], columns = [0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1] )\n",
    "df_3a = df_3a.multiply(100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(df_3a,xticklabels = 2, yticklabels = 5)\n",
    "plt.xlabel(\"α values\", fontsize = 12)\n",
    "plt.ylabel(\"β values\", fontsize = 12) \n",
    "ax.invert_yaxis()\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.set_label('% optimal action', labelpad=10, fontsize = 11)\n",
    "plt.savefig('70v10.png', bbox_inches='tight', dpi = 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
