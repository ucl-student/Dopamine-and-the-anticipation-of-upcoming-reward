{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from random import *\n",
    "import itertools \n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(beta, value):   \n",
    "    num = np.exp(value * beta)\n",
    "    den = np.exp(value * beta).sum()    \n",
    "    return num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parameter_fit(object):\n",
    "    def __init__(self, df, bounds = ((0,1), (0,5)), guess = [0.1,1]):\n",
    "        self.df = df\n",
    "        self.bounds = bounds # range for alpha and beta\n",
    "        self.guess = guess  # guess to aid scipy minimize\n",
    "        \n",
    "    def negative_log_likelihood(self, parameter):\n",
    "        df = self.df\n",
    "        alpha = parameter[0] # defining separate parameters\n",
    "        beta = parameter[1]\n",
    "        value = 0.5 * np.ones(2) # ensuring computes values for both levers/choices. Value starts at 0.5\n",
    "        \n",
    "        choices, rewards = df['right_or_left'].values.astype(int), df['reward'].values.astype(int)\n",
    "        prob_log = 0\n",
    "        session = df['session'].values.tolist()\n",
    "        switch = [i for i in range(1,len(session)) if session[i]!=session[i-1] ]\n",
    "        \n",
    "        \n",
    "        for choice, reward in zip(choices, rewards):\n",
    "            if choice not in switch:\n",
    "                value[choice] += alpha * (reward - value[choice])  \n",
    "            else:\n",
    "                value = 0.5\n",
    "            prob_log += np.log(softmax(value, beta)[choice])\n",
    "\n",
    "        return -prob_log\n",
    "\n",
    "    def minimisation(self):\n",
    "        bounds = (self.bounds)\n",
    "        mini = minimize(self.negative_log_likelihood, self.guess,\n",
    "                     method='L-BFGS-B',\n",
    "                     bounds=bounds)  # method is optimisation algorithm,\n",
    "        return mini\n",
    "\n",
    "    def data_fit(self):\n",
    "        data_fit = pd.DataFrame()\n",
    "        for mice in self.df['mouse'].unique().tolist():\n",
    "            df1 = self.df[self.df['mouse'] == mice]\n",
    "            df1 = df1.reset_index(drop = True)\n",
    "            mouse = df1['mouse'].unique().tolist()\n",
    "            sim = parameter_fit(df1,self.bounds,self.guess)\n",
    "            output = sim.minimisation()\n",
    "            data = pd.DataFrame({'mouse':mouse,'alpha':output.x[0],'beta':output.x[1],\n",
    "                                '- log likelihood':output.fun})\n",
    "            data_fit = data_fit.append(data)\n",
    "        return data_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.read_pickle('dlight_data.pkl')\n",
    "data = input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = data['session'].values.tolist() \n",
    "switch = [i for i in range(1,len(session)) if session[i]!=session[i-1] ]\n",
    "switch.append(len(session))\n",
    "block = list(np.diff(switch))\n",
    "block = [451] + block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [i for i in range(len(block))]\n",
    "temp = []\n",
    "for i, x in enumerate(block):\n",
    "    t = [name[i] for a in range(block[i])]\n",
    "    temp.append(t)\n",
    "flat_list = [item for sublist in temp for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mouse'] = flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = parameter_fit(data)\n",
    "fit = model.data_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RW_fit(alpha, left_value, right_value, reward, choices):\n",
    "    if choices == 1: #if right choice\n",
    "        delta = (reward - right_value)\n",
    "        right_value += alpha * (reward - right_value)  \n",
    "        left_value = left_value\n",
    "    elif choices == 0: #if left choice\n",
    "        delta = (reward - left_value)\n",
    "        left_value += alpha * (reward - left_value)     \n",
    "        right_value = right_value\n",
    "    return delta, left_value, right_value, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(mouse):  #calulating representations of value and rpe for each session\n",
    "    leftlever = 0.5\n",
    "    rightlever = 0.5\n",
    "    delta = []\n",
    "    left_value = [0.5]\n",
    "    right_value = [0.5]\n",
    "    \n",
    "    alpha = fit[fit['mouse']==mouse]['alpha'].item() \n",
    "    choices = data[data['mouse']==mouse]['right_or_left'].values.tolist() \n",
    "    session = data[data['mouse']==mouse]['session'].values.tolist() \n",
    "    reward = data[data['mouse']==mouse]['reward'].values.tolist()\n",
    "    transition = data[data['mouse']==mouse]['transition'].values.tolist()\n",
    "    correct = data[data['mouse']==mouse]['correct'].values.tolist()\n",
    "    block = [i for i in range(1,len(transition)) if transition[i]!=transition[i-1] ]\n",
    "    \n",
    "    for index, lr in enumerate(reward):  \n",
    "        if index in switch:\n",
    "            leftlever = 0.5\n",
    "            rightlever = 0.5\n",
    "            a, leftlever, rightlever = RW_fit(alpha, leftlever, rightlever, reward[index], choices[index])\n",
    "            delta.append(a)\n",
    "            left_value.append(leftlever)\n",
    "            right_value.append(rightlever)\n",
    "        else:\n",
    "            a, leftlever, rightlever = RW_fit(alpha, leftlever, rightlever, reward[index], choices[index])\n",
    "            delta.append(a)\n",
    "            left_value.append(leftlever)\n",
    "            right_value.append(rightlever)\n",
    "    \n",
    "    return delta, left_value, right_value, reward, choices, correct, block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta, left_value, right_value, reward, choices, correct, block = infer(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_unrewarded = []\n",
    "left_rewarded = []\n",
    "right_unrewarded = []\n",
    "right_rewarded = []\n",
    "\n",
    "for index, lr in enumerate(reward):\n",
    "    if choices[index] == 1: #if right choice\n",
    "        if reward[index] == 1:\n",
    "            right_rewarded.append(index)\n",
    "        elif reward[index]==0:\n",
    "            right_unrewarded.append(index)\n",
    "    elif choices[index] == 0: #if left choice\n",
    "        if reward[index] == 1:\n",
    "            left_rewarded.append(index)\n",
    "        elif reward[index]==0:\n",
    "            left_unrewarded.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = [110 for i in range(len(right_rewarded))] + [115 for i in range(len(right_unrewarded))] + [-10 for i in range(len(left_rewarded))]+[-15 for i in range(len(left_unrewarded))]\n",
    "rewarded = right_rewarded + right_unrewarded + left_rewarded + left_unrewarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewarded_df = pd.DataFrame({'rewarded':rewarded,'number':rr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = [i * 100 for i in choices]\n",
    "new_df = pd.DataFrame(new_list,\n",
    "                      columns =['Choices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['mean'] = new_df['Choices'].rolling(4, min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = new_df['mean'].plot(color = 'k')  #so 0 is left, 100 is right. Left was first correct\n",
    "plt.xlim(0,278)\n",
    "plt.ylim(-0.5,100.5)\n",
    "plt.axvspan(0, block[0], color='C0', alpha=0.5, lw=0)\n",
    "plt.axvspan(block[0], block[1], color='C1', alpha=0.5, lw=0)\n",
    "plt.axvspan(block[1], block[2], color='C0', alpha=0.5, lw=0)\n",
    "plt.axvspan(block[2], block[3], color='C1', alpha=0.5, lw=0)\n",
    "plt.axvspan(block[3], block[4], color='C0', alpha=0.5, lw=0)\n",
    "plt.axvspan(block[4], block[5], color='C1', alpha=0.5, lw=0)\n",
    "plt.axvspan(block[5], block[6], color='C0', alpha=0.5, lw=0)\n",
    "plt.axvspan(block[6], block[7], color='C1', alpha=0.5, lw=0)\n",
    "plt.axvspan(block[7], block[8], color='C0', alpha=0.5, lw=0)\n",
    "plt.axvspan(block[8], block[9], color='C1', alpha=0.5, lw=0)\n",
    "plt.axvspan(block[9], block[10], color='C0', alpha=0.5, lw=0)\n",
    "plt.ylabel('% right lever choice', fontsize = 14)\n",
    "ax.axes.get_xaxis().set_visible(False)\n",
    "sns.despine()\n",
    "plt.rcParams[\"figure.figsize\"] = (20,4)\n",
    "plt.savefig(\"4choices.png\", transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(left_value[:278], color = 'C0') #so left is blue\n",
    "plt.plot(right_value[:278], color = 'C1')\n",
    "plt.xlim(0,278)\n",
    "sns.despine(top=True, right=True, left=False, bottom=True)\n",
    "plt.ylabel('Action value', fontsize = 14)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "ax = plt.gca()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "plt.savefig(\"4value.png\", transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(delta, color = 'darkgreen')\n",
    "plt.xlim(0,278)\n",
    "sns.despine()\n",
    "plt.ylabel('RPE', fontsize = 14)\n",
    "plt.xlabel('Trials', fontsize = 14)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "plt.savefig(\"4rpe.png\", transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(right_rewarded, [110 for i in range(len(right_rewarded))] , 's', color='C1')\n",
    "plt.plot(right_unrewarded, [115 for i in range(len(right_unrewarded))], 'x', color = 'C1')\n",
    "plt.plot(left_rewarded, [-10 for i in range(len(left_rewarded))] , 's', color='C0')\n",
    "plt.plot(left_unrewarded, [-15 for i in range(len(left_unrewarded))] , 'x', color='C0')\n",
    "plt.xlim(0,278)\n",
    "plt.ylim(-20,120)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "sns.despine(top=True, right=True, left=False, bottom=True)\n",
    "ax = plt.gca()\n",
    "ax.axes.yaxis.set_visible(False)\n",
    "ax.get_xaxis().set_visible(False)\n",
    "plt.savefig(\"4rewardedtrials.png\", transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "legend_elements = [Line2D([0], [0], color='k', lw=2, label='Choice (4 trials running average)'),\n",
    "                   Patch(facecolor='C1',\n",
    "                         label='Right lever has higher reward %'),\n",
    "                   Patch(facecolor='C0',\n",
    "                         label='Left lever has higher reward %')]\n",
    "\n",
    "# Create the figure\n",
    "fig, ax = plt.subplots()\n",
    "ax.legend(handles=legend_elements, loc='center', frameon=False, prop={'size': 10})\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(\"4leg1.png\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "legend_elements = [Line2D([0], [0], color='C1', lw=2, label='Right lever'),\n",
    "                   Line2D([0], [0], color='C0', lw=2, label='Left lever'),\n",
    "                   Line2D([0], [0], color='darkgreen', lw=2, label='Reward prediction error')]\n",
    "\n",
    "# Create the figure\n",
    "fig, ax = plt.subplots()\n",
    "lgf = ax.legend(handles=legend_elements, loc='center', frameon=False, prop={'size': 10})\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(\"4leg3.png\", transparent=True, bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = plt.gca()\n",
    "axes.plot(right_rewarded, [110 for i in range(len(right_rewarded))] , 's', color='C1', label = 'Right rewarded trial')\n",
    "axes.plot(right_unrewarded, [115 for i in range(len(right_unrewarded))], 'x', color = 'C1', label = 'Right unrewarded trial')\n",
    "axes.plot(left_rewarded, [-10 for i in range(len(left_rewarded))] , 's', color='C0', label = 'Left rewarded trial')\n",
    "axes.plot(left_unrewarded, [-15 for i in range(len(left_unrewarded))] , 'x', color='C0', label = 'Left unrewarded trial')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "lgd = axes.legend(bbox_to_anchor=(1, 0.8), loc='upper left', frameon=False, prop={'size': 10})\n",
    "plt.savefig(\"4leg2.png\", transparent=True, bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
